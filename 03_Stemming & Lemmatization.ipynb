{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2c69613-e9e6-40e9-802c-6f6edda6e060",
   "metadata": {},
   "source": [
    "# Stemming & Lemmatization in NLP\n",
    "\n",
    "## Introduction\n",
    "When processing text, words often appear in **different forms**. For example:\n",
    "\n",
    "- `running`, `ran`, `runs` → root form is `run`\n",
    "- `better` → base form is `good`\n",
    "\n",
    "**Stemming** and **lemmatization** are techniques to **reduce words to their base forms**:\n",
    "\n",
    "| Technique       | Example                 | Output        |\n",
    "|-----------------|------------------------|---------------|\n",
    "| Stemming        | running, runs, ran      | run           |\n",
    "| Lemmatization   | better                  | good          |\n",
    "\n",
    "**Key Difference:**\n",
    "- **Stemming:** crude, removes suffixes (may not produce real words)\n",
    "- **Lemmatization:** more accurate, considers grammar and dictionary\n",
    "\n",
    "**In this notebook, we will learn:**\n",
    "1. Stemming using NLTK\n",
    "2. Lemmatization using NLTK\n",
    "3. Examples on a small dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05235f52-08e8-482d-9374-84fa2d46ef81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     D:\\miniconda_setup\\nltk_data...\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     D:\\miniconda_setup\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 0: Import libraries\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "\n",
    "# Download WordNet (required for lemmatization)\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e74ff02a-9312-44d8-a322-f08c76c33944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Words: ['running', 'ran', 'runs', 'easily', 'fairly']\n",
      "Stemmed Words: ['run', 'ran', 'run', 'easili', 'fairli']\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Stemming Example\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "words = [\"running\", \"ran\", \"runs\", \"easily\", \"fairly\"]\n",
    "stemmed_words = [stemmer.stem(w) for w in words]\n",
    "\n",
    "print(\"Original Words:\", words)\n",
    "print(\"Stemmed Words:\", stemmed_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83b5386-8767-4454-967f-0079f9a69fc9",
   "metadata": {},
   "source": [
    "**Explanation:**  \n",
    "- The stemmer removes common suffixes like `-ing`, `-s`.  \n",
    "- Output may not always be a real English word.  \n",
    "- Good for **search engines or fast preprocessing**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f19fc655-5ecd-4e1f-bb05-3fb3118d082e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Words: ['running', 'ran', 'runs', 'better', 'fairly']\n",
      "Lemmatized Words (verbs): ['run', 'run', 'run', 'better', 'fairly']\n",
      "Lemmatized Words (default/noun): ['running', 'ran', 'run', 'better', 'fairly']\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Lemmatization Example\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "words = [\"running\", \"ran\", \"runs\", \"better\", \"fairly\"]\n",
    "lemmatized_words = [lemmatizer.lemmatize(w, pos='v') for w in words]  # 'v' = verb\n",
    "\n",
    "print(\"Original Words:\", words)\n",
    "print(\"Lemmatized Words (verbs):\", lemmatized_words)\n",
    "\n",
    "# Lemmatization with default POS (noun)\n",
    "lemmatized_words_noun = [lemmatizer.lemmatize(w) for w in words]\n",
    "print(\"Lemmatized Words (default/noun):\", lemmatized_words_noun)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c305ed-f60b-4410-81fe-b242dfcc7ed6",
   "metadata": {},
   "source": [
    "**Explanation:**  \n",
    "- Lemmatization produces **real words**.  \n",
    "- We can specify **part-of-speech** (POS) for better accuracy (`v`=verb, `n`=noun, etc.)  \n",
    "- Works well for **text analysis and NLP pipelines**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47ee483a-c2fc-49a4-9e30-791914bbf92f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: The children are running faster than yesterday.\n",
      "Stemmed: ['the', 'children', 'are', 'run', 'faster', 'than', 'yesterday.']\n",
      "Lemmatized: ['The', 'children', 'be', 'run', 'faster', 'than', 'yesterday.']\n",
      "--------------------------------------------------\n",
      "Original: He runs every morning and enjoys it.\n",
      "Stemmed: ['he', 'run', 'everi', 'morn', 'and', 'enjoy', 'it.']\n",
      "Lemmatized: ['He', 'run', 'every', 'morning', 'and', 'enjoy', 'it.']\n",
      "--------------------------------------------------\n",
      "Original: She is better at playing football than me.\n",
      "Stemmed: ['she', 'is', 'better', 'at', 'play', 'footbal', 'than', 'me.']\n",
      "Lemmatized: ['She', 'be', 'better', 'at', 'play', 'football', 'than', 'me.']\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Stemming & Lemmatization on a Sample Dataset\n",
    "sample_texts = [\n",
    "    \"The children are running faster than yesterday.\",\n",
    "    \"He runs every morning and enjoys it.\",\n",
    "    \"She is better at playing football than me.\"\n",
    "]\n",
    "\n",
    "# Tokenize words\n",
    "tokenized_texts = [text.split() for text in sample_texts]\n",
    "\n",
    "for i, tokens in enumerate(tokenized_texts):\n",
    "    stemmed = [stemmer.stem(w) for w in tokens]\n",
    "    lemmatized = [lemmatizer.lemmatize(w, pos='v') for w in tokens]\n",
    "    print(f\"Original: {sample_texts[i]}\")\n",
    "    print(f\"Stemmed: {stemmed}\")\n",
    "    print(f\"Lemmatized: {lemmatized}\")\n",
    "    print('-'*50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe46c2d-2d07-4960-9ea0-48d8cace3d0d",
   "metadata": {},
   "source": [
    "- **Stemming**: Cuts words to root form, fast but may create non-words.  \n",
    "  - Example: running → run, easily → easi  \n",
    "- **Lemmatization**: Converts words to proper base form, considers grammar, accurate but slower.  \n",
    "  - Example: running → run, better → good  \n",
    "\n",
    "**Tips:**  \n",
    "1. Always tokenize first.  \n",
    "2. Use stemming for speed, lemmatization for accuracy.  \n",
    "3. Both reduce vocabulary size and help NLP models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f436af-cff5-4d52-b401-86660ba524f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
